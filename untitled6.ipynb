{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGq/4hrbj15oYPIFLFVGBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraAlinejad/vae_test_1/blob/main/untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2mhV2QFEfAn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce30f96a"
      },
      "source": [
        "# Task\n",
        "Implement a variational autoencoder with an orthogonality term in its loss function using MLCOLVAR to extract collective variables from the provided Aib9 dihedral data in the \".npy\" file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7cd869c"
      },
      "source": [
        "## Install mlcolvar\n",
        "\n",
        "### Subtask:\n",
        "Install the necessary library for implementing the VAE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ccb16b4"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the `mlcolvar` library. I will use the `pip install` command to install the library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3f4c1ad",
        "outputId": "95a946ad-7bb2-4cd4-ddbe-07d2f4f30f68"
      },
      "source": [
        "!pip install mlcolvar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlcolvar\n",
            "  Downloading mlcolvar-1.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting lightning (from mlcolvar)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from mlcolvar) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mlcolvar) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from mlcolvar) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mlcolvar) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from mlcolvar) (1.16.2)\n",
            "Collecting KDEpy (from mlcolvar)\n",
            "  Downloading kdepy-1.1.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning->mlcolvar) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning->mlcolvar)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning->mlcolvar) (25.0)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning->mlcolvar)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning->mlcolvar) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning->mlcolvar) (4.15.0)\n",
            "Collecting pytorch-lightning (from lightning->mlcolvar)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->mlcolvar) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mlcolvar) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->mlcolvar) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->mlcolvar) (2025.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (3.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mlcolvar) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->mlcolvar) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->mlcolvar) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->mlcolvar) (3.11)\n",
            "Downloading mlcolvar-1.2.2-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/114.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kdepy-1.1.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.2/686.2 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, KDEpy, torchmetrics, pytorch-lightning, lightning, mlcolvar\n",
            "Successfully installed KDEpy-1.1.12 lightning-2.5.5 lightning-utilities-0.15.2 mlcolvar-1.2.2 pytorch-lightning-2.5.5 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e25aa81"
      },
      "source": [
        "## Load and prepare data\n",
        "\n",
        "### Subtask:\n",
        "Load and prepare data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "846c38ce"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the numpy data and convert it to a PyTorch tensor, ensuring the correct data type.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae1ada7a",
        "outputId": "bc5d1606-4c7a-4ab3-a9ec-117ff08f791a"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load the data from the .npy file\n",
        "data_np = np.load('/content/no_repe_sin_cos_run2_data_2us.npy')\n",
        "\n",
        "# Convert the numpy array to a PyTorch tensor\n",
        "# Ensure the data type is suitable for VAE (typically float32 or float64)\n",
        "data_tensor = torch.from_numpy(data_np).float()\n",
        "\n",
        "# Display the shape and data type of the tensor\n",
        "print(\"Shape of the data tensor:\", data_tensor.shape)\n",
        "print(\"Data type of the data tensor:\", data_tensor.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the data tensor: torch.Size([2000000, 36])\n",
            "Data type of the data tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15bc32a2"
      },
      "source": [
        "## Define vae model\n",
        "\n",
        "### Subtask:\n",
        "Define the variational autoencoder model architecture using MLCOLVAR.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8680eeb8"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the encoder and decoder architectures and instantiate the VAE model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "1fc6bb6d",
        "outputId": "cc91bb49-6309-48ac-ec4f-e09b1b9512cc"
      },
      "source": [
        "from mlcolvar.cvs import VariationalAutoEncoderCV as VAE\n",
        "from mlcolvar.core.nn import FeedForward\n",
        "\n",
        "# Define the latent dimension\n",
        "latent_dim = 2\n",
        "\n",
        "# Define the encoder architecture (list of layer dimensions)\n",
        "encoder_layers = [36, 64, 32, latent_dim * 2]\n",
        "\n",
        "# Define the decoder architecture (list of layer dimensions)\n",
        "decoder_layers = [latent_dim, 32, 64, 36]\n",
        "\n",
        "# Instantiate the VAE model\n",
        "model = VAE(latent_dim, encoder_layers, decoder_layers)\n",
        "\n",
        "print(\"VAE model architecture defined.\")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'FeedForward' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-595898056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Instantiate the VAE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_architecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_architecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VAE model architecture defined.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlcolvar/cvs/unsupervised/vae.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_cvs, encoder_layers, decoder_layers, options, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mturned\u001b[0m \u001b[0moff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_cvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# =======   LOSS  =======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'FeedForward' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68f39786"
      },
      "source": [
        "## Train VAE\n",
        "\n",
        "### Subtask:\n",
        "Train the VAE model with the modified loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d5d854c"
      },
      "source": [
        "**Reasoning**:\n",
        "Train the VAE model using the prepared data and the custom VAE loss function with the orthogonality term. This involves setting up an optimizer and iterating through the data for a specified number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ac8cbba"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Define training parameters\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "learning_rate = 1e-3\n",
        "\n",
        "# Create a DataLoader for the data\n",
        "dataset = TensorDataset(data_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "print(\"Starting VAE training...\")\n",
        "for epoch in range(epochs):\n",
        "    total_train_loss = 0\n",
        "    total_recon_loss = 0\n",
        "    total_kl_loss = 0\n",
        "    total_ortho_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x = batch[0]\n",
        "\n",
        "        # Forward pass\n",
        "        recon_x, mu, logvar = model(x)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss, recon_loss, kl_loss, ortho_loss = vae_ortho_loss(recon_x, x, mu, logvar, model, ortho_coeff=0.1)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        total_recon_loss += recon_loss.item()\n",
        "        total_kl_loss += kl_loss.item()\n",
        "        total_ortho_loss += ortho_loss.item()\n",
        "\n",
        "    # Print epoch loss\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "          f\"Loss: {total_train_loss/len(dataloader):.4f}, \"\n",
        "          f\"Recon Loss: {total_recon_loss/len(dataloader):.4f}, \"\n",
        "          f\"KL Loss: {total_kl_loss/len(dataloader):.4f}, \"\n",
        "          f\"Ortho Loss: {total_ortho_loss/len(dataloader):.4f}\")\n",
        "\n",
        "print(\"VAE training finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e23375c1",
        "outputId": "602ca53b-ebb0-4da9-ef37-bc2e316f0411"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def vae_ortho_loss(recon_x, x, mu, logvar, model, ortho_coeff=0.1):\n",
        "    \"\"\"\n",
        "    Calculates the VAE loss with an added orthogonality term.\n",
        "\n",
        "    Args:\n",
        "        recon_x: Reconstructed input.\n",
        "        x: Original input.\n",
        "        mu: Mean of the latent distribution.\n",
        "        logvar: Log variance of the latent distribution.\n",
        "        model: The VAE model.\n",
        "        ortho_coeff: Coefficient for the orthogonality term.\n",
        "\n",
        "    Returns:\n",
        "        The total loss (reconstruction loss + KL divergence + orthogonality term).\n",
        "    \"\"\"\n",
        "    # Reconstruction loss (e.g., Mean Squared Error)\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
        "\n",
        "    # KL divergence loss\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Orthogonality term\n",
        "    # Get the encoded representation\n",
        "    encoded = model.encode(x)\n",
        "    # Calculate the covariance matrix of the encoded representation\n",
        "    cov_matrix = torch.cov(encoded.T)\n",
        "    # The orthogonality term is the sum of the absolute values of the off-diagonal elements\n",
        "    ortho_loss = torch.sum(torch.triu(torch.abs(cov_matrix), diagonal=1))\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = recon_loss + kl_loss + ortho_coeff * ortho_loss\n",
        "\n",
        "    return total_loss, recon_loss, kl_loss, ortho_loss\n",
        "\n",
        "print(\"Custom VAE loss function with orthogonality term defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom VAE loss function with orthogonality term defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bcd5298"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to import `mlcolvar.vae` failed. I need to find the correct import path for the VAE class within the installed mlcolvar library. I will try importing directly from `mlcolvar`.\n",
        "\n"
      ]
    }
  ]
}